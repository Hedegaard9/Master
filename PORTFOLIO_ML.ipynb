{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d659524d-2a47-47ef-9065-0bbf89bb2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features list length: 154\n"
     ]
    }
   ],
   "source": [
    "import Estimate_Covariance_Matrix as ECM\n",
    "from portfolio_choice_functions import ew_implement\n",
    "from prepare_portfolio_data import define_important_dates, create_date_ranges\n",
    "from Main import settings, features, pf_set\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from Prepare_Data import process_risk_free_rate, load_and_filter_market_returns_test, wealth_func\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import prepare_portfolio_data\n",
    "import data_run_files\n",
    "import Estimate_Covariance_Matrix\n",
    "import Prepare_Data\n",
    "import portfolio_choice_functions\n",
    "from portfolio_choice_functions import w_fun, m_func\n",
    "import portfolio_choice_functions\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import importlib\n",
    "import General_Functions\n",
    "sqrtm_cpp = importlib.import_module(\"sqrtm_cpp\")\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from return_prediction_functions import rff\n",
    "import General_Functions\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51213bef-ec06-4ef4-ad87-f300c323c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing excludes 0.60% of the observations\n",
      "Filen er indlæst og filtreret succesfuldt.\n",
      "No size screen\n",
      "Turnover wo addition/deletion rule: 0.19%\n",
      "Turnover w  addition/deletion rule: 33.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processerer datoer: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 164.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fil indlæst med succes. Antal rækker før filtrering: 1373911\n",
      "Antal ikke-NaN værdier i 'rvol_252d' i rvol_252 før merge: 2199588\n",
      "Antal ikke-NaN værdier i 'rvol_252d' i df efter merge: 1353529\n",
      "      id        eom  rvol_252d\n",
      "0  10006 1952-08-31   0.012671\n",
      "1  10006 1952-09-30   0.012712\n",
      "2  10006 1952-10-31   0.011661\n",
      "3  10006 1952-11-30   0.011523\n",
      "4  10006 1952-12-31   0.011812\n",
      "5  10006 1953-01-31   0.011484\n",
      "6  10006 1953-02-28   0.011835\n",
      "7  10006 1953-03-31   0.012331\n",
      "8  10006 1953-04-30   0.012696\n",
      "9  10006 1953-05-31   0.013877\n",
      "Filen 'usa_rvol.parquet' er gemt succesfuldt i ./Data mappen!\n",
      "Filen er indlæst og filtreret succesfuldt.\n",
      "All missing excludes 0.60% of the observations\n",
      "All missing excludes 0.60% of the observations\n",
      "Filen er indlæst og filtreret succesfuldt.\n",
      "No size screen\n",
      "Turnover wo addition/deletion rule: 0.19%\n",
      "Turnover w  addition/deletion rule: 33.72%\n",
      "df_merged head:\n",
      "      eom_ret     id        eom  valid_ret excntry         me   sic size_grp  \\\n",
      "0  1952-09-30  10006 1952-08-31       True     USA  23.885125  3740    small   \n",
      "1  1952-10-31  10006 1952-09-30       True     USA  22.076500  3740    small   \n",
      "2  1952-11-30  10006 1952-10-31       True     USA  21.088000  3740    small   \n",
      "3  1952-12-31  10006 1952-11-30       True     USA  23.476875  3740    small   \n",
      "4  1953-01-31  10006 1952-12-31       True     USA  24.218250  3740    small   \n",
      "\n",
      "   ret_exc_lead1m  niq_su  ...    ocf_at  ocf_at_chg1  mispricing_perf  \\\n",
      "0       -0.056756     NaN  ...  0.084642     0.038812         0.637818   \n",
      "1       -0.046028     NaN  ...  0.084642     0.038812         0.653567   \n",
      "2        0.112232     NaN  ...  0.084642     0.038812         0.497829   \n",
      "3        0.050879     NaN  ...  0.084642     0.038812         0.462569   \n",
      "4       -0.035634     NaN  ...  0.084642     0.038812         0.575019   \n",
      "\n",
      "   mispricing_mgmt  qmj  qmj_prof  qmj_growth  qmj_safety  ctff_test  \\\n",
      "0         0.669017  NaN  0.274990         NaN   -0.329044      False   \n",
      "1         0.627405  NaN  0.297905         NaN   -0.364834      False   \n",
      "2         0.625762  NaN  0.342228         NaN   -0.244439      False   \n",
      "3         0.626470  NaN  0.357438         NaN   -0.196596      False   \n",
      "4         0.667461  NaN  0.395463         NaN   -0.223198      False   \n",
      "\n",
      "   rvol_252d  \n",
      "0   0.012671  \n",
      "1   0.012712  \n",
      "2   0.011661  \n",
      "3   0.011523  \n",
      "4   0.011812  \n",
      "\n",
      "[5 rows x 164 columns]\n",
      "\n",
      "risk_free head:\n",
      "         eom      rf\n",
      "0 1926-07-31  0.0022\n",
      "1 1926-08-31  0.0025\n",
      "2 1926-09-30  0.0023\n",
      "3 1926-10-31  0.0032\n",
      "4 1926-11-30  0.0031\n",
      "\n",
      "market_test head:\n",
      "          eom  mkt_vw_exc\n",
      "0  2009-12-31    0.028217\n",
      "1  2010-01-31   -0.038043\n",
      "2  2010-02-28    0.034614\n",
      "3  2010-03-31    0.064495\n",
      "4  2010-04-30    0.019148\n",
      "\n",
      "data_ret_ld1 head:\n",
      "      id        eom    tr_ld0    eom_ret   ret_ld1    tr_ld1\n",
      "0  10104 2009-12-31       NaN 2010-01-31 -0.057916       NaN\n",
      "1  10104 2010-01-31       NaN 2010-02-28  0.068941  0.068941\n",
      "2  10104 2010-02-28  0.068941 2010-03-31  0.042934  0.042934\n",
      "3  10104 2010-03-31  0.042934 2010-04-30  0.007960  0.008060\n",
      "4  10104 2010-04-30  0.008060 2010-05-31 -0.127589 -0.127489\n",
      "\n",
      "wealth head:\n",
      "         eom  wealth  mu_ld1\n",
      "0 1926-06-30     NaN     NaN\n",
      "1 1926-07-31     NaN     NaN\n",
      "2 1926-08-31     NaN     NaN\n",
      "3 1926-09-30     NaN     NaN\n",
      "4 1926-10-31     NaN     NaN\n",
      "\n",
      "data head:\n",
      "      id        eom   sic size_grp            me  rvol_252d   dolvol_126d  \\\n",
      "0  10104 2009-12-31  7372     mega  122925.23004   0.020752  6.551683e+08   \n",
      "1  10104 2010-01-31  7372     mega  115558.73052   0.019544  6.798938e+08   \n",
      "2  10104 2010-02-28  7372     mega  123619.74809   0.018949  7.094750e+08   \n",
      "3  10104 2010-03-31  7372     mega  129040.82501   0.015241  6.982804e+08   \n",
      "4  10104 2010-04-30  7372     mega  130101.18774   0.014489  6.802223e+08   \n",
      "\n",
      "   age   aliq_at  aliq_mat  ...  taccruals_at  taccruals_ni  tangibility  \\\n",
      "0  300  0.526422  0.222711  ...     -0.040247     -0.378191     0.384579   \n",
      "1  301  0.526422  0.232151  ...     -0.040247     -0.378191     0.384579   \n",
      "2  302  0.526422  0.249602  ...     -0.040247     -0.378191     0.384579   \n",
      "3  303  0.570962  0.230516  ...     -0.009307     -0.086350     0.384579   \n",
      "4  304  0.570962  0.218079  ...     -0.009307     -0.086350     0.384579   \n",
      "\n",
      "   tax_gr1a  turnover_126d  turnover_var_126d  zero_trades_126d  \\\n",
      "0 -0.000151       0.005976           0.438638          0.002766   \n",
      "1 -0.000151       0.006062           0.439375          0.002792   \n",
      "2 -0.000151       0.006243           0.425637          0.002704   \n",
      "3  0.000186       0.005967           0.356592          0.002753   \n",
      "4  0.000186       0.005590           0.344846          0.002935   \n",
      "\n",
      "   zero_trades_21d  zero_trades_252d  rvol_252d  \n",
      "0         0.002710          0.002617   0.020752  \n",
      "1         0.002780          0.002652   0.019544  \n",
      "2         0.002416          0.002676   0.018949  \n",
      "3         0.002751          0.002807   0.015241  \n",
      "4         0.003165          0.002890   0.014489  \n",
      "\n",
      "[5 rows x 122 columns]\n",
      "\n",
      "chars head:\n",
      "       id        eom   sic size_grp            me  rvol_252d  dolvol_126d  \\\n",
      "12  10104 2010-12-31  7372     mega  158140.74215   0.430233     0.901163   \n",
      "13  10104 2011-01-31  7372     mega  161829.00643   0.430233     0.895349   \n",
      "14  10104 2011-02-28  7372     mega  166506.90772   0.447674     0.906977   \n",
      "15  10104 2011-03-31  7372     mega  169185.69576   0.500000     0.906977   \n",
      "16  10104 2011-04-30  7372     mega  181976.15073   0.534884     0.901163   \n",
      "\n",
      "         age   aliq_at  aliq_mat  ...        dolvol        lambda    rvol_m  \\\n",
      "12  0.270349  0.518519  0.229814  ...  8.750464e+08  2.285593e-10  0.070960   \n",
      "13  0.270349  0.469136  0.212500  ...  9.089283e+08  2.200394e-10  0.070226   \n",
      "14  0.270349  0.462963  0.181250  ...  9.388569e+08  2.130250e-10  0.070382   \n",
      "15  0.270349  0.586420  0.231250  ...  8.758167e+08  2.283583e-10  0.073779   \n",
      "16  0.270349  0.576687  0.216049  ...  8.577897e+08  2.331574e-10  0.074391   \n",
      "\n",
      "      tr_ld0    eom_ret   ret_ld1    tr_ld1    mu_ld0   ff12  valid  \n",
      "12  0.157290 2011-01-31  0.024854  0.024954  0.069873  BusEq  False  \n",
      "13  0.024954 2011-02-28  0.027040  0.027140  0.020052  BusEq  False  \n",
      "14  0.027140 2011-03-31  0.016118  0.016218  0.038821  BusEq  False  \n",
      "15  0.016218 2011-04-30  0.077342  0.077442  0.003383  BusEq  False  \n",
      "16  0.077442 2011-05-31 -0.048400 -0.048400  0.027662  BusEq  False  \n",
      "\n",
      "[5 rows x 130 columns]\n",
      "\n",
      "daily head:\n",
      "      id       date   ret_exc        eom\n",
      "0  10104 2009-12-31 -0.016048 2009-12-31\n",
      "1  10104 2010-01-04  0.013044 2010-01-31\n",
      "2  10104 2010-01-05 -0.001209 2010-01-31\n",
      "3  10104 2010-01-06 -0.014506 2010-01-31\n",
      "4  10104 2010-01-07 -0.003272 2010-01-31\n",
      "\n",
      "df_daily_returns head:\n",
      "      id       date   ret_exc        eom\n",
      "0  10104 2009-12-31 -0.016048 2009-12-31\n",
      "1  10104 2010-01-04  0.013044 2010-01-31\n",
      "2  10104 2010-01-05 -0.001209 2010-01-31\n",
      "3  10104 2010-01-06 -0.014506 2010-01-31\n",
      "4  10104 2010-01-07 -0.003272 2010-01-31\n",
      "Filtrering udført. Antal rækker efter filtrering: 179\n",
      "Fil gemt som ./data_test/risk_free_test.csv\n",
      "All missing excludes 0.63% of the observations\n",
      "All missing excludes 0.60% of the observations\n",
      "Filen er indlæst og filtreret succesfuldt.\n",
      "No size screen\n",
      "Turnover wo addition/deletion rule: 0.19%\n",
      "Turnover w  addition/deletion rule: 33.72%\n"
     ]
    }
   ],
   "source": [
    "# Path to save the portfolios.\n",
    "output_path = \"./data_test/\"\n",
    "\n",
    "\n",
    "# indhent barra_cov\n",
    "barra_cov = ECM.main()\n",
    "# indhent wealth\n",
    "wealth = Prepare_Data.main()\n",
    "wealth = wealth.dropna(subset=['wealth'])\n",
    "\n",
    "chars, lambda_list, first_cov_date, hp_years, start_oos, date_ranges, risk_free = prepare_portfolio_data.main(barra_cov)\n",
    "dates_m1 = date_ranges[\"dates_m1\"]\n",
    "dates_m2 = date_ranges[\"dates_m2\"]\n",
    "dates_oos = date_ranges[\"dates_oos\"]\n",
    "dates_hp = date_ranges[\"dates_hp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57de39-5837-4707-b082-32202911b455",
   "metadata": {},
   "source": [
    "# Hjælpefunktioner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5674e8a-c876-41b0-a7e4-30ce2a3c689a",
   "metadata": {},
   "source": [
    "## pfml_input_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c68f6-f663-4e76-b9e1-c89c97b9a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfolio-ML Inputs\n",
    "def pfml_input_fun(data_tc, cov_list, lambda_list, gamma_rel, wealth, mu, dates, lb, scale,\n",
    "                   risk_free, features, rff_feat, seed, p_max, g, add_orig, iter, balanced):\n",
    "    # --- Lookback-datoer ---\n",
    "    min_date = min(dates)\n",
    "    max_date = max(dates)\n",
    "    start_date = (min_date + pd.Timedelta(days=1)) - MonthEnd(lb + 1)\n",
    "    dates_lb = pd.date_range(start=start_date, end=max_date, freq=MonthEnd())\n",
    "    print(dates_lb)\n",
    "    # --- Oprettelse af Random Fourier Features ---\n",
    "    if rff_feat:\n",
    "        np.random.seed(seed)\n",
    "        X_features = data_tc[features].values\n",
    "        rff_x = rff(X_features, p=p_max, g=g)\n",
    "        rff_w = rff_x['W']\n",
    "        X_cos = rff_x['X_cos']\n",
    "        X_sin = rff_x['X_sin']\n",
    "        rff_features = np.hstack([X_cos, X_sin])\n",
    "        num = p_max // 2\n",
    "        rff_colnames = [f\"rff{i}_cos\" for i in range(1, num + 1)] + [f\"rff{i}_sin\" for i in range(1, num + 1)]\n",
    "        rff_df = pd.DataFrame(rff_features, columns=rff_colnames, index=data_tc.index)\n",
    "        data = pd.concat([data_tc[['id', 'eom', 'valid', 'ret_ld1', 'tr_ld0', 'mu_ld0']].reset_index(drop=True),\n",
    "                          rff_df.reset_index(drop=True)], axis=1)\n",
    "        feat_new = list(rff_df.columns)\n",
    "        if add_orig:\n",
    "            data = pd.concat([data, data_tc[features].reset_index(drop=True)], axis=1)\n",
    "            feat_new = feat_new + features\n",
    "    else:\n",
    "        cols = ['id', 'eom', 'valid', 'ret_ld1', 'tr_ld0', 'mu_ld0'] + features\n",
    "        data = data_tc[cols].copy()\n",
    "        feat_new = features.copy()\n",
    "\n",
    "    # Konverter 'eom' til string-format så vi får samme format i hele funktionen\n",
    "    data['eom'] = pd.to_datetime(data['eom']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    feat_cons = feat_new + ['constant']\n",
    "\n",
    "    # --- Tilføjelse af scales ---\n",
    "    if scale:\n",
    "        scales_list = []\n",
    "        for d in dates_lb:\n",
    "            d_str = d.strftime('%Y-%m-%d')\n",
    "            sigma = General_Functions.create_cov(cov_list[d_str])\n",
    "            if hasattr(sigma, 'values'):\n",
    "                sigma_vals = sigma.values\n",
    "                ids_sigma = sigma.index.astype(float)\n",
    "            else:\n",
    "                sigma_vals = sigma\n",
    "                ids_sigma = np.arange(sigma.shape[0])\n",
    "            diag_vol = np.sqrt(np.diag(sigma_vals))\n",
    "            df_scales = pd.DataFrame({\n",
    "                'id': ids_sigma,\n",
    "                'eom': d_str,  # Brug d_str for konsistens\n",
    "                'vol_scale': diag_vol\n",
    "            })\n",
    "            scales_list.append(df_scales)\n",
    "        scales_df = pd.concat(scales_list, ignore_index=True)\n",
    "        data = pd.merge(data, scales_df, on=['id', 'eom'], how='left')\n",
    "        data['vol_scale'] = data.groupby('eom')['vol_scale'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # --- Justering ved balanced panel ---\n",
    "    if balanced:\n",
    "        for col in feat_new:\n",
    "            data[col] = data.groupby('eom')[col].transform(lambda x: x - x.mean())\n",
    "        data['constant'] = 1\n",
    "        for col in feat_cons:\n",
    "            data[col] = data.groupby('eom')[col].transform(\n",
    "                lambda x: x * np.sqrt(1 / np.sum(x ** 2)) if np.sum(x ** 2) != 0 else 0)\n",
    "\n",
    "    # --- Beregning af signaler og realiseringer for hvert dato ---\n",
    "    reals_dict = {}\n",
    "    signal_t_dict = {}\n",
    "\n",
    "    for d in dates:\n",
    "        if d.year % 10 == 0 and d.month == 1:\n",
    "            print(f\"--> PF-ML inputs: {d}\")\n",
    "\n",
    "        d_str = d.strftime('%Y-%m-%d')\n",
    "        print(\"d\", d)\n",
    "        print(\"d_str\", d_str)\n",
    "        data_ret = data[(data['valid'] == True) & (data['eom'] == d_str)][['id', 'ret_ld1']]\n",
    "        ids = data_ret['id'].unique()  # ids som ints\n",
    "        n = len(ids)\n",
    "        r_vec = data_ret['ret_ld1'].values\n",
    "\n",
    "        # Brug de korrekte key-typer til både sigma og lambda\n",
    "        sigma = General_Functions.create_cov(cov_list[d_str], ids=ids)\n",
    "        lambda_series = pd.Series(lambda_list[d_str])\n",
    "        lambda_mat = General_Functions.create_lambda(lambda_series, ids=ids)\n",
    "\n",
    "        w = wealth.loc[wealth['eom'] == d_str, 'wealth'].iloc[0]\n",
    "        rf = risk_free.loc[risk_free['eom'] == d_str, 'rf'].iloc[0]\n",
    "        m = m_func(w=w, mu=mu, rf=rf, sigma_gam=sigma * gamma_rel, gam=gamma_rel,\n",
    "                   lambda_mat=lambda_mat, iter=iter)\n",
    "\n",
    "        # Brug MonthEnd til at beregne lower_bound – konverter til string-format\n",
    "        lower_bound = (d - MonthEnd(lb)).strftime('%Y-%m-%d')\n",
    "        data_sub = data[(data['id'].isin(ids)) & (data['eom'] >= lower_bound) & (data['eom'] <= d_str)].copy()\n",
    "\n",
    "        if not balanced:\n",
    "            for col in feat_new:\n",
    "                data_sub[col] = data_sub.groupby('eom')[col].transform(lambda x: x - x.mean())\n",
    "            data_sub['constant'] = 1\n",
    "            for col in feat_cons:\n",
    "                data_sub[col] = data_sub.groupby('eom')[col].transform(\n",
    "                    lambda x: x * np.sqrt(1 / np.sum(x ** 2)) if np.sum(x ** 2) != 0 else 0)\n",
    "\n",
    "        data_sub = data_sub.sort_values(by=['eom', 'id'], ascending=[False, True])\n",
    "        # Gruppér efter 'eom' – vi konverterer gruppenøglerne til string-format for konsistens\n",
    "        groups = {k: group for k, group in data_sub.groupby('eom')}\n",
    "\n",
    "        # Beregn signaler med diagnose: udskriv kun hvis NaN, Inf, tom DataFrame eller tomt index\n",
    "        signals = {}\n",
    "        for eom_val, group in groups.items():\n",
    "            if group.empty or group.index.empty:\n",
    "                print(f\"Advarsel: Gruppe for {eom_val} er tom!\")\n",
    "            s = group[feat_cons].values\n",
    "            if scale:\n",
    "                s = np.diag(1 / group['vol_scale'].values) @ s\n",
    "            # Tjek for NaN eller Inf\n",
    "            if np.isnan(s).any():\n",
    "                print(f\"Advarsel: Signal for {eom_val} indeholder NaN. Form: {s.shape}\")\n",
    "            if np.isinf(s).any():\n",
    "                print(f\"Advarsel: Signal for {eom_val} indeholder Inf. Form: {s.shape}\")\n",
    "            signals[eom_val] = s\n",
    "        print(\"signaler\", signals)\n",
    "        d_key = d_str  # d_str er allerede i '%Y-%m-%d'-format\n",
    "        signal_current = signals.get(d_key, None)\n",
    "        if signal_current is None:\n",
    "            print(f\"Advarsel: Ingen signal fundet for {d_key}.\")\n",
    "            continue\n",
    "        elif np.isnan(signal_current).any() or np.isinf(signal_current).any():\n",
    "            print(f\"Advarsel: Signal for {d_key} indeholder NaN eller Inf, springer denne dato over.\")\n",
    "            continue\n",
    "\n",
    "        # Beregn gtm for hver gruppe\n",
    "        gtm = {}\n",
    "        for eom_val, group in groups.items():\n",
    "            gt = (1 + group['tr_ld0']) / (1 + group['mu_ld0'])\n",
    "            gt = gt.fillna(1).values\n",
    "            gtm[eom_val] = m @ np.diag(gt)\n",
    "\n",
    "        # Aggregér gtm over lookback-perioden\n",
    "        n_stocks = n\n",
    "        gtm_agg = {}\n",
    "        gtm_agg_l1 = {}\n",
    "        gtm_agg[d_key] = np.eye(n_stocks)\n",
    "        gtm_agg_l1[d_key] = np.eye(n_stocks)\n",
    "        for i in range(1, lb + 1):\n",
    "            d_i = (d - MonthEnd(i)).strftime('%Y-%m-%d')\n",
    "            # DEBUG: Udskriv unikke 'eom'-datoer for denne lookback-dato\n",
    "            lookback_date = pd.to_datetime(d_i)\n",
    "            unique_dates = data[data['eom'] == lookback_date.strftime('%Y-%m-%d')]['eom'].unique()\n",
    "            print(f\"Lookup for lookback-dato: {d_i} - Unikke eom-datoer fundet: {unique_dates}\")\n",
    "\n",
    "            if d_i in gtm:\n",
    "                gtm_agg[d_i] = gtm_agg[list(gtm_agg.keys())[-1]] @ gtm[d_i]\n",
    "            else:\n",
    "                gtm_agg[d_i] = gtm_agg[list(gtm_agg.keys())[-1]]\n",
    "            d_i_l1 = (d - MonthEnd(i + 1)).strftime('%Y-%m-%d')\n",
    "            if d_i_l1 in gtm:\n",
    "                gtm_agg_l1[d_i] = gtm_agg_l1[list(gtm_agg_l1.keys())[-1]] @ gtm[d_i_l1]\n",
    "            else:\n",
    "                gtm_agg_l1[d_i] = gtm_agg_l1[list(gtm_agg_l1.keys())[-1]]\n",
    "\n",
    "        # Summering over lookback: opbyg omega og konstanter\n",
    "        omega_sum = None\n",
    "        const_sum = None\n",
    "        omega_l1_sum = None\n",
    "        const_l1_sum = None\n",
    "        for i in range(0, lb + 1):\n",
    "            d_i = (d - MonthEnd(i)).strftime('%Y-%m-%d')\n",
    "            s_i = signals.get(d_i, None)\n",
    "            if s_i is None:\n",
    "                print(f\"Advarsel: Ingen signal fundet for lookback-dato d_i {d_i}\")\n",
    "                term = np.zeros((n_stocks, len(feat_cons)))\n",
    "            else:\n",
    "                term = gtm_agg.get(d_i, np.eye(n_stocks)) @ s_i\n",
    "            if omega_sum is None:\n",
    "                omega_sum = term\n",
    "                const_sum = gtm_agg.get(d_i, np.eye(n_stocks))\n",
    "            else:\n",
    "                omega_sum = omega_sum + term\n",
    "                const_sum = const_sum + gtm_agg.get(d_i, np.eye(n_stocks))\n",
    "\n",
    "            d_i_l1 = (d - MonthEnd(i + 1)).strftime('%Y-%m-%d')\n",
    "            s_i_l1 = signals.get(d_i_l1, None)\n",
    "            if s_i_l1 is None:\n",
    "                print(f\"Advarsel: Ingen signal fundet for lookback-dato d_i_l1 {d_i_l1}\")\n",
    "                term_l1 = np.zeros((n_stocks, len(feat_cons)))\n",
    "            else:\n",
    "                term_l1 = gtm_agg_l1.get(d_i_l1, np.eye(n_stocks)) @ s_i_l1\n",
    "            if omega_l1_sum is None:\n",
    "                omega_l1_sum = term_l1\n",
    "                const_l1_sum = gtm_agg_l1.get(d_i_l1, np.eye(n_stocks))\n",
    "            else:\n",
    "                omega_l1_sum = omega_l1_sum + term_l1\n",
    "                const_l1_sum = const_l1_sum + gtm_agg_l1.get(d_i_l1, np.eye(n_stocks))\n",
    "\n",
    "        # Løs de lineære systemer\n",
    "        omega_final = np.linalg.solve(const_sum, omega_sum)\n",
    "        omega_l1_final = np.linalg.solve(const_l1_sum, omega_l1_sum)\n",
    "\n",
    "        # Beregn gt for den aktuelle gruppe (d)\n",
    "        if d_key in signals:\n",
    "            group_d = groups.get(d_key, None)\n",
    "            if group_d is None:\n",
    "                gt_vec = np.ones(n_stocks)\n",
    "            else:\n",
    "                gt_vec = ((1 + group_d['tr_ld0']) / (1 + group_d['mu_ld0'])).values\n",
    "            gt_mat = np.diag(gt_vec)\n",
    "        else:\n",
    "            gt_mat = np.eye(n_stocks)\n",
    "\n",
    "        omega_chg = omega_final - gt_mat @ omega_l1_final\n",
    "\n",
    "        # --- Realiseringer ---\n",
    "        r_tilde = omega_final.T @ r_vec\n",
    "        risk_val = gamma_rel * (omega_final.T @ sigma @ omega_final)\n",
    "        tc_val = w * (omega_chg.T @ lambda_mat @ omega_chg)\n",
    "        denom = risk_val + tc_val\n",
    "\n",
    "        reals = {\n",
    "            \"r_tilde\": r_tilde.item() if np.isscalar(r_tilde) or r_tilde.size == 1 else r_tilde,\n",
    "            \"denom\": denom.item() if np.isscalar(denom) or denom.size == 1 else denom,\n",
    "            \"risk\": risk_val.item() if np.isscalar(risk_val) or risk_val.size == 1 else risk_val,\n",
    "            \"tc\": tc_val.item() if np.isscalar(tc_val) or tc_val.size == 1 else tc_val\n",
    "        }\n",
    "\n",
    "        reals_dict[d_key] = reals\n",
    "        signal_t_dict[d_key] = signals.get(d_key, None)\n",
    "\n",
    "    return {\"reals\": reals_dict, \"signal_t\": signal_t_dict, \"rff_w\": rff_w if rff_feat else None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078199b-442b-49cd-a38d-eb2cc2fc32d9",
   "metadata": {},
   "source": [
    "## pfml_feat_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aac71b-88a3-471f-acde-7279ca232be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names\n",
    "def pfml_feat_fun(p, orig_feat, features=None):\n",
    "    \"\"\"\n",
    "    Returnerer en liste af feature-navne.\n",
    "\n",
    "    Parametre:\n",
    "      p         : Antal RFF-features (skal være deleligt med 2). Hvis p er 0, bruges ingen RFF-features.\n",
    "      orig_feat : Bool – om de originale features skal inkluderes.\n",
    "      features  : Liste af originale feature-navne. Skal gives, hvis orig_feat er True.\n",
    "\n",
    "    Returnerer:\n",
    "      En liste med feature-navne.\n",
    "    \"\"\"\n",
    "    feat = [\"constant\"]\n",
    "    if p != 0:\n",
    "        half_p = p // 2\n",
    "        feat.extend([f\"rff{i}_cos\" for i in range(1, half_p + 1)])\n",
    "        feat.extend([f\"rff{i}_sin\" for i in range(1, half_p + 1)])\n",
    "    if orig_feat and features is not None:\n",
    "        feat.extend(features)\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81507ee-ad88-4184-aa1d-adcea09a9fa2",
   "metadata": {},
   "source": [
    "## denom_sum_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867788b4-1bd6-418e-8d9e-4229cd524d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean of denom matrices before hp_years\n",
    "def denom_sum_fun(train):\n",
    "    \"\"\"\n",
    "    Beregner summen af 'denom'-værdier fra en liste af træningsdata.\n",
    "    \n",
    "    Parametre:\n",
    "      train : Liste af ordbøger, hvor hver ordbog indeholder en nøgle 'denom'.\n",
    "      \n",
    "    Returnerer:\n",
    "      Summen af alle 'denom'-værdier.\n",
    "    \"\"\"\n",
    "    # Hvis 'denom' er et tal eller en numpy-array, summeres de med sum().\n",
    "    return sum(x['denom'] for x in train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846a6c9-f7a2-42b6-a2a1-df465cc73d99",
   "metadata": {},
   "source": [
    "## pfml_search_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255ba70-6fa6-49d8-a28f-9d147620a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper search for best coefficients ---------------------\n",
    "def pfml_search_coef(pfml_input, p_vec, l_vec, hp_years, orig_feat):\n",
    "    # Konverter nøglerne (datoer) til datetime-objekter\n",
    "    reals = pfml_input[\"reals\"]\n",
    "    # Vi antager, at nøglerne kan konverteres med pd.to_datetime\n",
    "    d_all = {pd.to_datetime(k): k for k in reals.keys()}\n",
    "    \n",
    "    # Bestem end_bef = min(hp_years) - 1 (fx hvis det mindste hp_year er 2016, så er end_bef 2015)\n",
    "    end_bef = 2021  # - 1\n",
    "    # Vælg træningsdata før: datoer < (min(hp_years)-2)-12-31\n",
    "    cutoff_date = pd.to_datetime(f\"{end_bef - 1}-12-31\")\n",
    "    train_bef = {k: reals[d_all[k]] for k in d_all if k < cutoff_date}\n",
    "    \n",
    "    # Beregn sum af r_tilde over træningssættet.\n",
    "    # Her antages det, at hver x['r_tilde'] er en pandas Series med index svarende til feature-navne.\n",
    "    r_tilde_list = [item['r_tilde'] for item in train_bef.values()]\n",
    "    # Summering: her benyttes sum() til pandas Series (forudsætter, at listen ikke er tom)\n",
    "    r_tilde_sum = sum(r_tilde_list) if r_tilde_list else pd.Series(0)\n",
    "    \n",
    "    # Tilsvarende: sum af 'denom'-matricer (antages at være pandas DataFrames med feature-navne som index/columns)\n",
    "    denom_list = [item['denom'] for item in train_bef.values()]\n",
    "    denom_raw_sum = sum(denom_list) if denom_list else pd.DataFrame(0)\n",
    "    \n",
    "    # n er antallet af observationer i train_bef\n",
    "    n = len(train_bef) # skal evt ændres\n",
    "    \n",
    "    # Sorter hp_years, og opret en ordbog til at holde koefficienterne\n",
    "    hp_years = sorted(hp_years)\n",
    "    coef_list = {}\n",
    "    \n",
    "    # For hvert hp_year\n",
    "    for hp in hp_years:\n",
    "        # Udvælg nye træningsobservationer: datoer i intervallet\n",
    "        # [ (hp-2)-12-31, (hp-1)-11-30 ]\n",
    "        lower_bound = pd.to_datetime(f\"{hp - 2}-12-31\")\n",
    "        upper_bound = pd.to_datetime(f\"{hp - 1}-11-30\")\n",
    "        \n",
    "        train_new = {k: reals[d_all[k]] for k in d_all if lower_bound <= k <= upper_bound}\n",
    "        \n",
    "        # Opdater antallet af observationer\n",
    "        n += len(train_new)\n",
    "        # Opdater r_tilde_sum med de nye r_tilde-værdier\n",
    "        r_tilde_new = sum([item['r_tilde'] for item in train_new.values()]) if len(train_new) > 0 else 0\n",
    "        r_tilde_sum = r_tilde_sum + r_tilde_new\n",
    "    \n",
    "        \n",
    "    # Opdater denom-summen\n",
    "    denom_raw_new = sum([item['denom'] for item in train_new.values()]) if len(train_new) > 0 else 0\n",
    "    denom_raw_sum = denom_raw_sum + denom_raw_new\n",
    "    \n",
    "    # For hvert p i p_vec, beregn de tilhørende koefficienter\n",
    "    coef_by_hp = {}\n",
    "    # Hent feature-navnene givet p og om de originale features skal medtages\n",
    "    feat_p = pfml_feat_fun(p, orig_feat)\n",
    "    all_feat = feat_p\n",
    "    # r_tilde_sub: udtræk de features fra r_tilde_sum og divider med n\n",
    "    r_tilde_sum = pd.Series(r_tilde_sum, index=all_feat)\n",
    "    \n",
    "    r_tilde_sub = r_tilde_sum.loc[feat_p] / n\n",
    "    # denom_sub: udtræk de relevante rækker og kolonner fra denom_raw_sum og divider med n\n",
    "    denom_raw_sum.index = all_feat\n",
    "    denom_raw_sum.columns = all_feat\n",
    "    \n",
    "    denom_sub = denom_raw_sum.loc[feat_p, feat_p] / n\n",
    "        \n",
    "    results = {}\n",
    "    for l in l_vec:\n",
    "        M = denom_sub + l * np.eye(len(feat_p))\n",
    "        # Løs det lineære system: M * coef = r_tilde_sub\n",
    "        coef = np.linalg.solve(M.values, r_tilde_sub.values)\n",
    "        # Gem resultatet som en pandas Series med index = feat_p\n",
    "        results[l] = pd.Series(coef, index=feat_p)\n",
    "    # Gem resultaterne for den aktuelle p-værdi\n",
    "    coef_by_hp[p] = results\n",
    "    # Gem koefficienterne for det aktuelle hp_year, brug hp som streng\n",
    "    coef_list[str(hp)] = coef_by_hp\n",
    "        \n",
    "    return coef_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788213fb-4ec4-4fda-adff-a159247117b0",
   "metadata": {},
   "source": [
    "## pfml_hp_reals_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692da8c-87ec-446d-9859-f2f0e3c86bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, compute realized utility for each p in each hp_year -------------------\n",
    "def pfml_hp_reals_fun(pfml_input, hp_coef, p_vec, l_vec, hp_years, orig_feat):\n",
    "\n",
    "    # Konverter nøglerne for pfml_input[\"reals\"] til pd.Timestamp og opret en mapping\n",
    "    reals_all_raw = pfml_input[\"reals\"]\n",
    "    reals_all_dict = {pd.to_datetime(k): v for k, v in reals_all_raw.items()}\n",
    "\n",
    "    # Liste til at samle alle rækker\n",
    "    rows = []\n",
    "\n",
    "    # For hvert hp_year (bruges som 'end')\n",
    "    for end in sorted(hp_years):\n",
    "        # Vælg observationer med datoer: >= (end-1)-12-31 og <= end-11-30\n",
    "        lower_bound = pd.to_datetime(f\"{end - 1}-12-31\")\n",
    "        upper_bound = pd.to_datetime(f\"{end}-11-30\")\n",
    "        # Filtrer reals for dette hp_year\n",
    "        reals_all = {dt: obj for dt, obj in reals_all_dict.items() if lower_bound <= dt <= upper_bound}\n",
    "        \n",
    "        # Hent koefficienterne for dette hp_year\n",
    "        coef_list_yr = hp_coef[str(end)]\n",
    "        \n",
    "        # For hvert p i p_vec\n",
    "        for p in p_vec:\n",
    "            # Hent de relevante feature-navne for p\n",
    "            feat_p = pfml_feat_fun(p, orig_feat)  # Forudsætter at funktionen er defineret\n",
    "            # Hent koefficientlisten for denne p-værdi (nøglen som string)\n",
    "            coef_list_p = coef_list_yr[str(p)]\n",
    "            \n",
    "            # For hver observation i reals_all: udtræk r_tilde og denom for feat_p\n",
    "            reals_subset = {}\n",
    "            for dt, obj in reals_all.items():\n",
    "                # Restriktion af r_tilde og denom til de features, der er i feat_p\n",
    "                r_tilde_sub = obj[\"r_tilde\"][feat_p]\n",
    "                denom_sub = obj[\"denom\"].loc[feat_p, feat_p]\n",
    "                reals_subset[dt] = {\"r_tilde\": r_tilde_sub, \"denom\": denom_sub}\n",
    "            \n",
    "            # For hver l-værdi (brug indeks i l_vec)\n",
    "            for i, l_value in enumerate(l_vec):\n",
    "                # Hent koefficienten for denne l-værdi\n",
    "                coef = coef_list_p[i]  # Forventet at være en pandas Series med index = feat_p\n",
    "                # For hver dato (nøgle) i reals_subset, beregn realiseret nytte\n",
    "                for dt, sub_obj in reals_subset.items():\n",
    "                    # Beregn: r = t(r_tilde) %*% coef - 0.5 * t(coef) %*% denom %*% coef\n",
    "                    r_val = sub_obj[\"r_tilde\"].dot(coef) - 0.5 * (coef.dot(sub_obj[\"denom\"].dot(coef)))\n",
    "                    # Beregn eom_ret: her beregnes som månedsslut for næste måned\n",
    "                    eom_ret = dt + MonthEnd(1)\n",
    "                    # Gem række med de relevante oplysninger\n",
    "                    rows.append({\n",
    "                        \"eom\": dt,\n",
    "                        \"eom_ret\": eom_ret,\n",
    "                        \"obj\": r_val,\n",
    "                        \"l\": l_value,\n",
    "                        \"p\": p,\n",
    "                        \"hp_end\": end\n",
    "                    })\n",
    "\n",
    "    # Sammensæt resultaterne til et DataFrame\n",
    "    validation = pd.DataFrame(rows)\n",
    "    \n",
    "    # Sorter efter p, l og eom_ret\n",
    "    validation = validation.sort_values(by=[\"p\", \"l\", \"eom_ret\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Beregn kumulativ middelværdi af 'obj' for hver gruppe (p, l) i kronologisk rækkefølge af eom_ret.\n",
    "    validation[\"cum_obj\"] = validation.groupby([\"p\", \"l\"])[\"obj\"].transform(lambda x: x.expanding().mean())\n",
    "    \n",
    "    # For hver eom_ret, beregn rangeringen af -cum_obj (dvs. højere cum_obj giver lavere ranknummer)\n",
    "    validation[\"rank\"] = validation.groupby(\"eom_ret\")[\"cum_obj\"].rank(ascending=False)\n",
    "    \n",
    "    return validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f093e5-79c0-456b-b751-44e35b862a22",
   "metadata": {},
   "source": [
    "## pfml_aims_fun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8d70b-a820-4523-ad53-f41aaf067b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimal aim portfolio (for a given g) -----------------\n",
    "def pfml_aims_fun(pfml_input, validation, data_tc, hp_coef, hp_years, dates_oos, l_vec, orig_feat):\n",
    "    \"\"\"\n",
    "    Opretter den optimale AIM-portefølje (for et g) baseret på de fundne hyperparametre.\n",
    "    \n",
    "    Parametre:\n",
    "      pfml_input : Dictionary med nøglen \"signal_t\". Her skal pfml_input[\"signal_t\"] være en dictionary,\n",
    "                   hvor nøglerne er dato-strenge (fx \"2020-01-31\") og værdier er DataFrames med signaler.\n",
    "      validation : Pandas DataFrame med bl.a. kolonnerne 'eom_ret', 'rank', 'l' og 'p'.\n",
    "                   Her antages 'eom_ret' at være datetime, så vi kan udlede året.\n",
    "      data_tc    : Pandas DataFrame med portefølje-data, indeholdende mindst 'id', 'eom' og 'valid'.\n",
    "      hp_coef    : Dictionary med koefficienter for hvert out-of-sample år. Strukturen er:\n",
    "                   hp_coef[str(oos_year)][str(p)][l_index] = koefficient (pandas Series).\n",
    "      hp_years   : Liste med hp-år (fx [2016, 2017, ...]).\n",
    "      dates_oos  : Liste af out-of-sample datoer (pd.Timestamp objekter).\n",
    "      l_vec      : Liste med lambda-værdier.\n",
    "      orig_feat  : Boolean, angivende om de originale features skal medtages.\n",
    "      \n",
    "    Returnerer:\n",
    "      aim_pfs_list : Dictionary med nøgler svarende til hver dato i dates_oos, hvor hver værdi er en dictionary med nøglerne:\n",
    "                     \"aim_pf\" : DataFrame med kolonnerne 'id', 'eom' og 'w_aim'.\n",
    "                     \"coef\"   : Den valgte koefficient (pandas Series) for den aktuelle dato.\n",
    "    \"\"\"\n",
    "    # Udvælg optimum hyperparametre: de rækker hvor eom_ret er i december og rank==1,\n",
    "    # og udled hp_end som året fra eom_ret.\n",
    "    validation = validation.copy()\n",
    "    validation['hp_end'] = validation['eom_ret'].dt.year\n",
    "    opt_hps = validation[(validation['eom_ret'].dt.month == 12) & (validation['rank'] == 1)][['hp_end', 'l', 'p']]\n",
    "    \n",
    "    print(\"Optimum hyperparametre (opt_hps):\")\n",
    "    print(opt_hps)\n",
    "    \n",
    "    aim_pfs_list = {}\n",
    "    \n",
    "    for d in dates_oos:\n",
    "        # Udregn d_ret svarende til: d + 1 + måneder(1) - 1 \n",
    "        # (dvs. at få månedsslut for den næste måned)\n",
    "        d_ret = d + pd.Timedelta(days=1) + DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        print(\"d_ret:\")\n",
    "        print(d_ret)\n",
    "        \n",
    "        oos_year = d_ret.year\n",
    "        print(\"oos_year:\")\n",
    "        print(oos_year)\n",
    "        \n",
    "        # Vælg hp_year: hvis (oos_year - 1) findes blandt opt_hps.hp_end, så brug det,\n",
    "        # ellers bruges den mindste værdi af opt_hps.hp_end.\n",
    "        if (oos_year - 1) in opt_hps['hp_end'].values:\n",
    "            hp_year = oos_year - 1\n",
    "        else:\n",
    "            hp_year = opt_hps['hp_end'].min()\n",
    "        print(\"hp_year:\")\n",
    "        print(hp_year)\n",
    "        \n",
    "        # Vælg de hyperparametre, der matcher hp_year\n",
    "        hps_d = opt_hps[opt_hps['hp_end'] == hp_year]\n",
    "        print(\"hps_d:\")\n",
    "        print(hps_d)\n",
    "        \n",
    "        if hps_d.empty:\n",
    "            print(f\"Ingen hyperparameter fundet for hp_year: {hp_year} til dato: {d_ret}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Hyperparameter for hp_year {hp_year}:\")\n",
    "            print(hps_d)\n",
    "        \n",
    "        # Antag at der kun er én række – ellers kan man tage den første\n",
    "        p_val = hps_d['p'].iloc[0]\n",
    "        print(p_val)\n",
    "        l_val = hps_d['l'].iloc[0]\n",
    "        print(l_val)\n",
    "        # Hent de relevante features via pfml_feat_fun (skal være defineret)\n",
    "        feat = pfml_feat_fun(p=p_val, orig_feat=orig_feat)\n",
    "        \n",
    "        # Hent signalerne for dato d. Vi antager, at nøglerne i pfml_input[\"signal_t\"] er i ISO-format.\n",
    "        key_d = d.strftime('%Y-%m-%d')\n",
    "        s = pfml_input[\"signal_t\"][key_d][feat]\n",
    "        \n",
    "        # Find indeks for l_val i l_vec (brug evt. en tilnærmelsesmetode for floating point)\n",
    "        try:\n",
    "            l_no = l_vec.index(l_val)\n",
    "        except ValueError:\n",
    "            l_no = min(range(len(l_vec)), key=lambda i: abs(l_vec[i] - l_val))\n",
    "        \n",
    "        # Hent den korrekte koefficient\n",
    "        key_oos_year = str(oos_year)\n",
    "        key_p = str(p_val)\n",
    "        coef = hp_coef[key_oos_year][key_p][l_no]\n",
    "        \n",
    "        # Filtrer data_tc for rækker, hvor valid==True og eom == d\n",
    "        aim_pf_data = data_tc[(data_tc['valid'] == True) & (data_tc['eom'] == d)].copy()\n",
    "        # Beregn w_aim = s %*% coef. Her antages det, at s er en DataFrame med samme rækkefølge som\n",
    "        # de relevante rækker i data_tc, og at coef er en pandas Series med index svarende til kolonnerne i s.\n",
    "        aim_pf_data['w_aim'] = s.dot(coef)\n",
    "        aim_pf = aim_pf_data[['id', 'eom', 'w_aim']]\n",
    "        \n",
    "        aim_pfs_list[d] = {\"aim_pf\": aim_pf, \"coef\": coef}\n",
    "    \n",
    "    return aim_pfs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9d331-2088-45a3-baff-b070e2f5417d",
   "metadata": {},
   "source": [
    "## pfml_w  mangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d464b84-b46f-404a-9ee3-5317c30214ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1b499-79b5-4e92-9acc-148c26383a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50513209-7b0a-48cf-8782-d3e1ac107793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e78e1d-0e29-4b99-8763-674f84236c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289177f1-4652-4bbb-a686-9712c7ac446f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd536587-2bc0-4b5d-8942-18da02f40c53",
   "metadata": {},
   "source": [
    "# Implementation FUNCTION SIDSTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e725d24-0184-41ac-9f91-f4ee1e8e0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfml_implement(data_tc, cov_list, lambda_list, risk_free, features, \n",
    "                   wealth, mu, gamma_rel, dates_full, dates_oos, lb, \n",
    "                   hp_years, rff_feat, scale, \n",
    "                   g_vec=None, p_vec=None, l_vec=None, orig_feat=None, iter=None, hps=None, balanced=None, seed=None):\n",
    "    #data_tc = data_tc[(data_tc['valid'] == True) & (data_tc['eom'].isin(dates_oos))].copy() # forsøg med dato\n",
    "    # Hyperparameter search ----------\n",
    "    if hps is None:\n",
    "        start_time = time.time()\n",
    "        hps = {}\n",
    "        # Loop over hvert g i g_vec\n",
    "        for g in g_vec:\n",
    "            start_g = time.time()\n",
    "            # Step 1: Prepare data\n",
    "            # Antag at pfml_input_fun returnerer en dictionary med nøglerne 'rff_w', 'reals' og 'signal_t'\n",
    "            pfml_input = pfml_input_fun(\n",
    "                data_tc, wealth=wealth, mu=mu, dates=dates_full,\n",
    "                lb=lb, scale=scale, risk_free=risk_free,\n",
    "                cov_list=cov_list, lambda_list=lambda_list, gamma_rel=gamma_rel, iter=iter,\n",
    "                features=features, balanced=balanced,\n",
    "                rff_feat=rff_feat, p_max=max(p_vec), g=g, add_orig=orig_feat, seed=seed\n",
    "            )\n",
    "            print(\"pfml_input_fun took {:.2f} sec\".format(time.time()-start_g))\n",
    "            # RFF weights\n",
    "            rff_w = pfml_input['rff_w']\n",
    "            # Inputs – antag at pfml_feat_fun returnerer en liste/array med de ønskede indeks\n",
    "            feat_all = pfml_feat_fun(p=max(p_vec), orig_feat=orig_feat)\n",
    "            # Juster pfml_input, så de relevante matricer/vektorer kun indeholder de kolonner, der svarer til feat_all\n",
    "            pfml_input = adjust_pfml_input(pfml_input, feat_all)\n",
    "            # (Bemærk: Linjen nedenfor fjernes, da adjust_pfml_input allerede håndterer signal_t)\n",
    "            # pfml_input['signal_t'] = {k: x[:, feat_all] for k, x in pfml_input['signal_t'].items()}\n",
    "            \n",
    "            # Coefficients – antag at pfml_search_coef er en Python‑funktion\n",
    "            pfml_hp_coef = pfml_search_coef(pfml_input, p_vec=p_vec, l_vec=l_vec, hp_years=hp_years, orig_feat=orig_feat)\n",
    "            # Realized utility – antag at pfml_hp_reals_fun returnerer en DataFrame\n",
    "            validation = pfml_hp_reals_fun(pfml_input, hp_coef=pfml_hp_coef, p_vec=p_vec, l_vec=l_vec, hp_years=hp_years, orig_feat=orig_feat)\n",
    "            validation['g'] = g  # Tilføj kolonnen g med den nuværende værdi\n",
    "            # Find optimal aim portfolio – antag at pfml_aims_fun er implementeret\n",
    "            print(\"--------------------------------\")\n",
    "            aims = pfml_aims_fun(pfml_input, validation=validation, data_tc=data_tc, hp_coef=pfml_hp_coef, hp_years=hp_years, dates_oos=dates_oos, l_vec=l_vec, orig_feat=orig_feat)\n",
    "            elapsed_g = (time.time() - start_g) / 60\n",
    "            print(f\"g: {g:.2f} took {elapsed_g:.2f} min\")\n",
    "            # Gem resultaterne for dette g\n",
    "            hps[str(g)] = {\"aim_pfs_list\": aims, \"validation\": validation, \"rff_w\": rff_w}\n",
    "        print(\"Total hyperparameter search took {:.2f} sec\".format(time.time()-start_time))\n",
    "\n",
    "    print(\"hps efter kørsel\", hps)\n",
    "    # Implement final portfolio -----------------\n",
    "    # Kombinér alle validation-DataFrames fra hps til én DataFrame (uden 'rank'-kolonnen)\n",
    "    validation_list = [hp_dict[\"validation\"] for hp_dict in hps.values()]\n",
    "    print(\"validation_list\", validation_list)\n",
    "    best_hps = pd.concat(validation_list, ignore_index=True)\n",
    "    print(\"best_hps\", best_hps)\n",
    "    if 'rank' in best_hps.columns:\n",
    "        best_hps = best_hps.drop(columns='rank')\n",
    "    # Beregn rank pr. eom_ret-gruppe: rank baseret på -cum_obj (højere cum_obj = lavere rank)\n",
    "    best_hps['rank'] = best_hps.groupby('eom_ret')['cum_obj'].rank(ascending=False, method='min')\n",
    "    # Vælg de rækker, hvor rank == 1 og eom_ret er i december\n",
    "    best_hps['eom_ret'] = pd.to_datetime(best_hps['eom_ret'])\n",
    "    best_hps = best_hps[(best_hps['rank'] == 2.5) & (best_hps['eom_ret'].dt.month == 12)]\n",
    "    \n",
    "    # Tjek at hyperparameter-området er passende: Lav et plot af parametrene p, l og g mod eom_ret\n",
    "    melt_df = best_hps.melt(id_vars=['eom_ret'], value_vars=['p', 'l', 'g'], var_name='param', value_name='value')\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.scatterplot(data=melt_df, x='eom_ret', y='value', hue='param', alpha=0.5)\n",
    "    # sns.lineplot(data=melt_df, x='eom_ret', y='value', hue='param')\n",
    "    # plt.title(\"HP Range Check\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # Aim portfolios: For hver dato i dates_oos\n",
    "    best_hps_list = {}\n",
    "    for d in dates_oos:\n",
    "        # d_ret beregnes som den sidste dag i den næste måned:\n",
    "        d_ret = d + pd.offsets.MonthEnd(1)\n",
    "        oos_year = d_ret.year\n",
    "        # Vælg rækker i best_hps for år = oos_year - 1\n",
    "        print(best_hps)\n",
    "        bh = best_hps[best_hps['eom_ret'].dt.year == (oos_year)] #== (oos_year - 1)]\n",
    "        if bh.empty:\n",
    "            continue\n",
    "        best_g = bh['g'].iloc[0]\n",
    "        best_p = bh['p'].iloc[0]\n",
    "        d_str = d.strftime('%Y-%m-%d')\n",
    "        # Hent best_aim og best_coef fra hps; antag at aim_pfs_list er en dictionary med nøgler svarende til datoer (som strenge)\n",
    "        print(\"Aim_pfs_list keys for best_g:\", list(hps[str(best_g)][\"aim_pfs_list\"].keys()))\n",
    "        print(\"Lookup key d_str:\", d_str)\n",
    "\n",
    "        best_aim = hps[str(best_g)][\"aim_pfs_list\"][d_str][\"aim_pf\"]\n",
    "        best_coef = hps[str(best_g)][\"aim_pfs_list\"][d_str][\"coef\"]\n",
    "        best_hps_list[d_str] = {\"g\": best_g, \"p\": best_p, \"aim\": best_aim, \"coef\": best_coef}\n",
    "    \n",
    "    # Kombinér alle aim-portfolios fra best_hps_list til en DataFrame\n",
    "    aims_list = [item[\"aim\"] for item in best_hps_list.values()]\n",
    "    aims = pd.concat(aims_list, ignore_index=True)\n",
    "    \n",
    "    # Final portfolio: Vælg data_tc for datoer i dates_oos og hvor valid == True\n",
    "    w_data = data_tc[(data_tc['valid'] == True) & (data_tc['eom'].isin(dates_oos))][['id', 'eom', 'eom_ret', 'me', 'tr_ld1', 'valid']].copy()\n",
    "    # Antag at pfml_w er en Python‑funktion, der returnerer en DataFrame med de beregnede vægte\n",
    "    w = pfml_w(w_data, dates=dates_oos, cov_list=cov_list, lambda_list=lambda_list, gamma_rel=gamma_rel, iter=iter, risk_free=risk_free, wealth=wealth, mu=mu, aims=aims)\n",
    "    \n",
    "    pf = pf_ts_fun(w, data=data_tc, wealth=wealth, gam=gamma_rel)\n",
    "    pf['type'] = \"Portfolio-ML\"\n",
    "    \n",
    "    # List of Ws used: Lav en dictionary med nøgler fra g_vec og værdier fra hps['rff_w']\n",
    "    rff_w_list = {g: hps[str(g)][\"rff_w\"] for g in g_vec}\n",
    "    \n",
    "    return {\"hps\": hps, \"best_hps\": best_hps, \"best_hps_list\": best_hps_list, \"aims\": aims, \"w\": w, \"pf\": pf, \"rff_w_list\": rff_w_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66d3ee-72b2-41c5-b252-fcf40e9c1273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6c85a-3c8c-4223-a4de-a2a2f30ac661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e97e2-4068-4b8e-a667-3e659067f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02324396-2827-4dbe-9b4b-de488f6a1455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
